# rag_basic

a demo project to illustrate basic concepts of RAG

## How to use it?

### 1. 环境设置
#### (1) 设置运行环境变量
在你的运行环境设置以下变量：
- `ALICLOUD_ACCESS_KEY_ID`
- `ALICLOUD_ACCESS_KEY_SECRET`
- `DASHSCOPE_API_KEY`

#### (2) 修改配置文件
修改 `config.py`，根据你的需求，更改 `llm`、`embedding`、`retrieval` 等配置项。

### 2. 生成本地索引
#### (1) 放置法律文件
把需要查询的法律文件（pdf 格式）放到 `data/raw/legal` 目录下。

#### (2) 放置基金文件
把需要查询的基金文件（pdf 格式）放到 `data/raw/fund` 目录下。

#### (3) 运行脚本
运行 `python vector_index.py rebuild index`。

#### (4) 检查生成文件
检查 `data/embeddings` 目录，里面有 FAISS 生成的本地文件。

### 3. 运行查询
#### (1) 创建问题文件
在 `agent.py` 的同目录下，创建一个 `question.txt` 文件，以换行符为分隔，放入查询语句。

#### (2) 执行查询脚本
运行 `python agent.py`。

#### (3) 获取查询结果
在 `agent.py` 的同目录下，会生成 `answer.txt` 文件，里面是查询结果。

### 4. 编辑运行端到端测试
#### (1) 找到测试文件
端到端测试文件在 `tests/test_end_to_end.py`。

#### (2) 运行测试
执行 `python -m pytest tests/`

## TODO

由于时间非常有限，并且作者缺乏一些主流 AI 产品的付费账号，所以目前这个项目的完善度还很低。下面列出主要的待完善项目。

### 1. 处理 PDF 中文本信息
当前的实现方案只是把文本按照固定大小分块。实际上，不论是法律文件还是基金文件，特别是法律文件，它的内容有严格的层级关系。存储的时候，如果用元数据记录这种层级关系，可以很好的提升查询能力。

在 `pdf_processor/text.py` 中，做了一些简单的尝试，按照法律文件中的一级标题、二级标题等给文本分块，再把同一个顶层块的所有子块进行合并输出。但时间有限，代码本身有 bug，目前的 `build index` 没有用到这一部分算法。

还有一种方案是用 `Neo4jGraph` 来专门存储层级关系，最后查询的时候进行混合查询。

### 2. 处理 PDF 中的表格
除了表格本身固有的由于其结构和自然语言表达的结构差异带来的查询效率问题以外，还发现了两个问题。一个是如何识别表的 `title`，一个是如何把跨页的表合并成一个。在 `pdf_processor/table.py` 中，对 `pdfplumber` 和 `camelot` 两个类库都做了些测试，目前的效果还不够好。感觉想要比较好的处理表格的问题，可能需要对 pdf 进行一定程度的预处理。

### 3. 处理 PDF 中的图片
本来最好是能把每一张图片的信息单独存在一个 `block` 里面，但试了 `pytesseract` 之后发现，它如果直接从 pdf 上提取图片的话，对样例文件的图片识别的准确率太低。最后采取的方案是，把整个 `page` 当作一幅图片，做整个页面的 OCR。这样其实让向量库多存了一部分文字信息（被 OCR 出来的文字），需要优化。

### 4. 处理 PDF 中的公式
由于没有 `mathpix` 的相关权限，最后用了百度云的公式识别，效果很差。这个部分目前基本属于不可用。